{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93180a76-7622-4cbe-8c7c-bed40a76f2fe",
   "metadata": {},
   "source": [
    "## ESTUDOS DE REGRESSÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583876a-6046-45b4-bdf8-6cbe0e607bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS, summarize, poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bec77-fc82-4a62-8130-83598dea1eeb",
   "metadata": {},
   "source": [
    "### RESUMO INTRODUCTION TO STATISTICAL LEARNING\n",
    "**3.1 Regressão Linear Simples** (p. 69)\n",
    "* **Definição**:\n",
    "   * Modela a relação entre uma variável resposta Y e uma única variável preditora X.\n",
    "   * Equação do modelo: Y = β0 + β1X + ϵ.\n",
    "   * O objetivo é estimar os coeficientes β0 (intercepto) e β1 (inclinação) que minimizam o erro quadrático (RSS - Residual Sum of Squares).    \n",
    "### **3.1.1 Estimação dos Coeficientes**:\n",
    "- Os coeficientes são estimados usando o método dos **mínimos quadrados**.\n",
    "- Fórmulas para $ \\beta_0 $ e $ \\beta_1 $:\n",
    "  $\n",
    "  \\displaystyle \\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}\n",
    "  $\n",
    "  $\n",
    "  \\displaystyle \\beta_0 = \\bar{y} - \\beta_1 \\bar{x}\n",
    "  $\n",
    "- Essas fórmulas garantem que a linha de regressão seja a que melhor se ajusta aos dados, minimizando a soma dos quadrados dos resíduos.\n",
    "* **3.1.2 Avaliação do Modelo**:\n",
    "   * **RSE (Residual Standard Error)**: Mede o desvio padrão dos resíduos. Quanto menor o RSE, melhor o ajuste do modelo. RSE = √(∑ᵢ₌₁ⁿ(yi−ŷi)²)/(n−p−1)\n",
    "   * **R² (Coeficiente de Determinação)**: Proporção da variância em Y explicada por X. R² = 1 − RSS/TSS, TSS = ∑(yi−ȳ)²\n",
    "   * Um valor de R² próximo de 1 indica que o modelo explica grande parte da variabilidade da resposta.\n",
    "---\n",
    "\n",
    "### **3.2 Regressão Linear Múltipla** (p. 81)\n",
    "- **Definição**:\n",
    "  - Modela a relação entre $ Y $ e várias variáveis preditoras $ X_1, X_2, \\dots, X_p $.\n",
    "  - Equação do modelo: $ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon $.\n",
    "- **3.2.1 Estimação dos Coeficientes**:\n",
    "  - Os coeficientes são estimados minimizando o RSS, agora em um espaço multidimensional.\n",
    "  - A solução pode ser expressa em forma matricial:\n",
    "    $ \\hat{\\beta} = (X^T X)^{-1} X^T Y $\n",
    "  - Onde $ X $ é a matriz de preditores e $ Y $ é o vetor de respostas.\n",
    "- **3.2.2 Avaliação do Modelo**:\n",
    "  - **Teste F**: Verifica se pelo menos um dos preditores tem relação significativa com $ Y $.\n",
    "    $ F = \\frac{(TSS - RSS)/p}{RSS/(n - p - 1)} $\n",
    "    Um valor grande de $ F $ sugere que pelo menos um preditor é significativo.\n",
    "  - **Teste t**: Avalia a significância individual de cada coeficiente.\n",
    "    $ t = \\frac{\\hat{\\beta}_j}{SE(\\hat{\\beta}_j)} $\n",
    "    Um valor absoluto grande de $ t $ indica que o preditor $ X_j $ é significativo.\n",
    "\n",
    "---\n",
    "\n",
    "### **3.3 Seleção de Variáveis** (p. 86)\n",
    "- **3.3.1 Métodos para Seleção**:\n",
    "  - **Seleção Forward**: Adiciona preditores um a um, começando com o modelo vazio. Em cada passo, o preditor que mais reduz o RSS é adicionado.\n",
    "  - **Seleção Backward**: Remove preditores um a um, começando com o modelo completo. Em cada passo, o preditor que menos contribui para o modelo é removido.\n",
    "  - **Seleção Mista**: Combina forward e backward, permitindo que preditores sejam adicionados ou removidos em cada passo.\n",
    "- **3.3.2 Critérios de Seleção**:\n",
    "  - **R² Ajustado**: Penaliza a adição de preditores irrelevantes.\n",
    "    $ R^2_{\\text{ajustado}} = 1 - \\frac{RSS/(n - p - 1)}{TSS/(n - 1)} $\n",
    "  - **Cp de Mallow**, **AIC**, **BIC**: Medem o trade-off entre ajuste e complexidade.\n",
    "    $ C_p = \\frac{RSS}{\\hat{\\sigma}^2} + 2p, \\quad AIC = n \\log(RSS) + 2p, \\quad BIC = n \\log(RSS) + p \\log(n) $\n",
    "\n",
    "---\n",
    "\n",
    "### **3.4 Interações e Termos Não Lineares** (p. 95)\n",
    "\n",
    "- **3.4.1 Interações**:<br>\n",
    "  - Permitem que o efeito de um preditor dependa do valor de outro.<br>\n",
    "  - Exemplo: $ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1 X_2 + \\epsilon $.<br>\n",
    "  - O termo de interação $ X_1 X_2 $ captura a sinergia entre os preditores.<br>\n",
    "- **3.4.2 Termos Não Lineares**:<br>\n",
    "  - Podem ser incluídos usando transformações (e.g., $ X^2 $, $ \\log(X) $).<br>\n",
    "  - Exemplo: $ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon $.<br>\n",
    "  - Isso permite que o modelo capture relações não lineares entre $ X $ e $ Y $.<br>\n",
    "\n",
    "---\n",
    "\n",
    "### **3.5 Problemas Potenciais em Regressão Linear** (p. 100)\n",
    "\n",
    "- **3.5.1 Não Linearidade**:  \n",
    "  A relação entre $ Y $ e $ X $ pode não ser linear. Solução: usar transformações ou modelos não lineares.  \n",
    "- **3.5.2 Correlação dos Erros**:  \n",
    "  Erros correlacionados podem invalidar inferências. Comum em dados temporais.  \n",
    "- **3.5.3 Heterocedasticidade**:  \n",
    "  Variância dos erros não é constante. Solução: transformar $ Y $ ou usar mínimos quadrados ponderados.  \n",
    "- **3.5.4 Outliers e Pontos de Alavancagem**:  \n",
    "  Observações extremas podem distorcer o modelo. Solução: identificar e remover outliers.  \n",
    "- **3.5.5 Multicolinearidade**:  \n",
    "  Preditores altamente correlacionados podem inflar a variância das estimativas. Solução: remover preditores redundantes ou usar técnicas como PCA.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3.6 Comparação com K-Nearest Neighbors (KNN)** (p. 111)\n",
    "\n",
    "- **3.6.1 KNN**:  \n",
    "  Método não paramétrico que prevê $Y$ com base nos $K$ vizinhos mais próximos.  \n",
    "  Vantagem: flexibilidade para capturar relações não lineares.  \n",
    "  Desvantagem: desempenho ruim em alta dimensionalidade (maldição da dimensionalidade).\n",
    "- **3.6.2 Comparação**:  \n",
    "  Regressão linear é melhor quando a relação verdadeira é linear ou próxima disso.  \n",
    "  KNN pode ser superior em relações não lineares, mas sofre com o aumento do número de preditores.\n",
    "---\n",
    "\n",
    "### **Equações Importantes**\n",
    "1. **Regressão Simples**:\n",
    "   $ Y = \\beta_0 + \\beta_1 X + \\epsilon $\n",
    "2. **Regressão Múltipla**:\n",
    "   $ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p + \\epsilon $\n",
    "3. **RSS (Residual Sum of Squares)**:\n",
    "   $ RSS = \\sum (y_i - \\hat{y}_i)^2 $\n",
    "4. **R²**:\n",
    "   $ R^2 = 1 - \\frac{RSS}{TSS}, \\quad TSS = \\sum (y_i - \\bar{y})^2 $\n",
    "5. **Teste F**:\n",
    "   $ F = \\frac{(TSS - RSS)/p}{RSS/(n - p - 1)} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b5d320-a9f5-456b-b51d-ccfed45600dc",
   "metadata": {},
   "source": [
    "#Projeto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e4ae4-d367-4c83-997d-7c2c5996b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boston = load_data(\"Boston\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a776e-c985-4484-a226-4f764aad82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192cb0a0-a84e-4ac1-8d77-ab3899d4d7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
